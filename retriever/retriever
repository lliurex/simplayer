#!/usr/bin/env python3
import sys
from tracemalloc import start
import requests
from pprint import pprint
import os
import json
import re
import shutil
import time
import signal
import subprocess
from bs4 import BeautifulSoup as bs

info_parsed = []
folder = 'retriever_data'
cache_file = f'{folder}/cacheinfo.json'
cache_file_full = f'{folder}/fullcache.json'
repos = f'{folder}/repos'
output = f'{folder}/output'
exit_now = False

def exitnow(*args,**kwargs):
    print('Exitting')
    exit_now = True
    sys.exit(1)

signal.signal(signal.SIGINT,exitnow)

def get_info():
    url="https://api.github.com/users/phetsims/repos?per_page=100&page=1"
    info_parsed = {}
    cache = []
    while True:
        try:
            r = requests.get(url)
            links=dict([ (i.split(';')[1].strip().split('"')[1],i.split(';')[0].strip()) for i in r.headers.get('Link').split(',')])
            info = r.json()
            cache.extend(info)
            for repo in info:
                info_parsed.setdefault(repo.get('name'), {'license': (repo.get('license') or {}).get('name'), 'url': repo.get('html_url') , 'description': repo.get('description') } )
            if not links.get('last'):
                break
            else:
                url=''.join([ x for x in links.get('next') if x not in '<>' ])
        except Exception as e:
            break
    if not os.path.isdir(folder):
        os.mkdir(folder)
    with open(cache_file,'w') as f:
        json.dump(info_parsed,f,ensure_ascii=False,indent=4)
    with open(cache_file_full,'w') as f:
        json.dump(cache,f,ensure_ascii=False,indent=4)
    return info_parsed

def get_mappings():
    categories={}
    projects={}
    if os.path.isfile('mapping'):
        with open('mapping','r') as f:
            content = f.readlines()
            cat = None
            for line in content:
                if line[0] == '[':
                    cat = line.strip().split('[')[1].split(']')[0]
                    categories.setdefault(cat,[])
                else:
                    projects.setdefault(line.strip(),[])
                    projects[line.strip()].append(cat)
                    categories[cat].append(line.strip())
    return (categories,projects)

def get_meta_name(data):
    try:
        soup = bs(data,'lxml')
        title = soup.head.title.text.encode('latin1','ignore').decode('latin1')
        return title
    except Exception as e:
        print(f'Error: {e}')
        sys.exit(1)

if __name__ == '__main__':
    time_start=time.time()
    print('Fetching metadata from Github')
    if not os.path.isfile(cache_file):
        info_parsed = get_info()
    else:
        try:
            with open(cache_file,'r') as f:
                info_parsed = json.load(f)
        except Exception as e:
            sys.exit(1)
    print(f'{len(info_parsed)} repositories found')
    simulations = [x for x in info_parsed if 'educational simulation' in (info_parsed.get(x).get('description') or '')]
    print(f'{len(simulations)} simulations found')
    for name in simulations:
        output_path=f'{output}/{name}'
        if os.path.isdir(output_path):
            missing=0
            png_path=f'{output_path}/{name}.png'
            if not os.path.isfile(png_path):
                print(f'Warning: {png_path} missing')
                missing=missing+1
            html_path=f'{output_path}/{name}.html'
            if not os.path.isfile(html_path):
                print(f'Warning: {html_path} missing')
                missing=missing+1
            if missing == 2:
                print(f'Deleting: {output_path} !')
                shutil.rmtree(output_path)
    simulations = [x for x in simulations if not os.path.isdir(f'{output}/{x}')]
    print(f'{len(simulations)} simulations pending for build')
    for name in simulations:
        repo_path = f'{repos}/{name}'
        if not os.path.isdir(repo_path):
            repo = info_parsed.get(name).get('url')
            print(f'Downloading git {name}')
            os.system(f'git clone {repo} {repo_path} >/dev/null 2>&1')
    simulations = [ sim for sim in simulations if os.path.isfile(f'{repos}/{sim}/README.md') ]
    print(f'{len(simulations)} valid simulations')
    completed=0
    for name in simulations:
        if exit_now:
            break
        stime=time.time()
        print(f'Processing {simulations.index(name)+1}/{len(simulations)}: {name}')
        readme_path = f'{repos}/{name}/README.md'
        with open(readme_path,'r') as f:
            content=f.readlines()
            devel = False
            in_dev_dependencies = False
            in_install_dependencies = False
            start_script = False
            end = False
            gits = []
            scripts = []
            for line in content:
                if not devel:
                    if re.search('under development',line,re.IGNORECASE):
                        devel = True
                        break
                    if re.search('clone the simulation and its dependencies',line,re.IGNORECASE):
                        in_dev_dependencies = True
                    if in_dev_dependencies:
                        m=re.search('git clone .*',line,re.IGNORECASE)
                        if m:
                            gits.append(m.group(0))
                        m=re.search('install dev dependencies',line,re.IGNORECASE)
                        if m:
                            in_dev_dependencies = False
                            in_install_dependencies = True
                    if in_install_dependencies:
                        if '```' in line:
                            if not start_script:
                                start_script = True
                            else:
                                in_install_dependencies = False
                                end = True
                                break
                        else:
                            if start_script:
                                if line[:3] not in ['cd ','npm']:
                                    print(f'unknown script in {name}')
                                    sys.exit(1)
                                scripts.append(line.strip())
                    if end:
                        break
            if devel:
                print(f'{name} is under development, skipping')
                continue
            for url in ( gitcmd.split(' ')[2] for gitcmd in gits ):
                dep = os.path.basename(url).split('.')[0]
                if dep not in simulations:
                    repo_path=f'{repos}/{dep}'
                    if dep == 'perennial':
                        repo_path = f'{repos}/perennial-alias'
                    if not os.path.isdir(repo_path):
                        os.system(f'git clone {url} {repo_path} >/dev/null 2>&1')
                        print(f'Clonning {dep}')
            cwd=os.path.realpath(os.curdir)
            try:
                for scr in scripts:
                    if 'cd ' in scr:
                        dirname = os.path.basename(scr.split(' ')[1])
                        if os.path.isdir(f'{repos}/{dirname}'):
                            subprocess.check_output('npm install >/dev/null 2>&1',shell=True,cwd=f'{repos}/{dirname}')
                subprocess.check_output('node js/scripts/transpile.js >/dev/null 2>&1',shell=True,cwd=f'{repos}/chipper')
                subprocess.check_output('npm install >/dev/null 2>&1',shell=True,cwd=f'{repos}/{name}')
                subprocess.check_output('npm install grunt-cli >/dev/null 2>&1',shell=True,cwd=f'{repos}/{name}')
                subprocess.check_output('./node_modules/grunt-cli/bin/grunt --brands=adapted-from-phet --locales=es,ca  >/dev/null 2>&1',shell=True,cwd=f'{repos}/{name}')
            except Exception as e:
                print(f'{e}')
            if not os.path.isdir(f'{output}'):
                os.mkdir(f'{output}')
            if not os.path.isdir(f'{output}/{name}'):
                os.mkdir(f'{output}/{name}')
            builddir = f'{repos}/{name}/build/adapted-from-phet'
            metalangs = []
            for lang in ['es','ca']:
                if os.path.isfile(f'{builddir}/{name}-600.png'):
                    shutil.copy(f'{builddir}/{name}-600.png',f'{output}/{name}/{name}.png')
                if os.path.isfile(f'{builddir}/{name}_{lang}_adapted-from-phet.html'):
                    metalangs.append(lang)
                    shutil.copy(f'{builddir}/{name}_{lang}_adapted-from-phet.html',f'{output}/{name}/{name}_{lang}.html')
            metadata = {}
            categories, projects = get_mappings()
            metadata.setdefault('languages',metalangs)
            for lang in metalangs:
                metaname = f'_{lang}'
                trname = name
                try:
                    with open(f'{output}/{name}/{name}_{lang}.html','r') as fp:
                        trname = get_meta_name(fp.read())
                except Exception as e:
                    pass
                metadata.setdefault(f'name{metaname}',f'{trname}')
                metadata.setdefault(f'banner{metaname}',f'{name}.png')
                metadata.setdefault(f'html{metaname}',f'{name}{metaname}.html')
            projects.setdefault(name,[])
            metadata.setdefault('category',','.join(projects[name]))
            metadata.setdefault('require',"")
            for k,v in info_parsed.get(name).items():
                metadata.setdefault(k,v)
            with open(f'{output}/{name}/meta.json','w') as f:
                json.dump(metadata,f,ensure_ascii=False)
            print(f'{name} completed [{int(time.time()-stime)} s]')
            completed=completed+1
    print(f'End {completed} builds [{int(time.time()-time_start)} s]')
